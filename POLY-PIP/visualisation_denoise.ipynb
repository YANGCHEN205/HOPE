{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "from scipy import io\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "from modules import utils\n",
    "from modules.models import INR\n",
    "from torchsummary import summary\n",
    "from modules.encoding import Encoding\n",
    "from encoding import MultiResHashGrid\n",
    "import lpips\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "def get_noisy_image(img_np, sigma):\n",
    "    \"\"\"Adds Gaussian noise to an image.\n",
    "    \n",
    "    Args: \n",
    "        img_np: image, np.array with values from 0 to 1\n",
    "        sigma: std of the noise\n",
    "    \"\"\"\n",
    "    img_noisy_np = np.clip(img_np + np.random.normal(scale=sigma, size=img_np.shape), 0, 1).astype(np.float32)\n",
    "\n",
    "    return img_noisy_np\n",
    "\n",
    "lpips_vgg_model = lpips.LPIPS(net=\"vgg\")\n",
    "lpips_alex_model = lpips.LPIPS(net=\"alex\")\n",
    "folder_path = '/home/wrt/Poly/INCODE-main/data/image'\n",
    "\n",
    "parser = argparse.ArgumentParser(description='INCODE')\n",
    "# Shared Parameters\n",
    "parser.add_argument('--input',type=str, default='/root/autodl-tmp/INCODE-main/data/0640.png', help='Input image path')\n",
    "# parser.add_argument('--input',type=str, default='/home/wrt/Poly/deep-image/data/denoising/F16_GT.png', help='Input image path')\n",
    "parser.add_argument('--inr_model',type=str, default='incode', help='[gauss, mfn, relu, siren, wire, wire2d, ffn, incode]')\n",
    "parser.add_argument('--lr',type=float, default=5e-4, help='Learning rate')\n",
    "parser.add_argument('--using_schedular', type=bool, default=True, help='Whether to use schedular')\n",
    "parser.add_argument('--scheduler_b', type=float, default=0.01, help='LR scheduler [set it from 0.05 to 0.1]')\n",
    "parser.add_argument('--maxpoints', type=int, default=512*512, help='Batch size')\n",
    "parser.add_argument('--niters', type=int, default=2001, help='Number if iterations')\n",
    "parser.add_argument('--steps_til_summary', type=int, default=10, help='Number of steps till summary visualization')\n",
    "# INCODE Parameters\n",
    "parser.add_argument('--a_coef',type=float, default=0.1993, help='a coeficient')\n",
    "parser.add_argument('--b_coef',type=float, default=0.0196, help='b coeficient')\n",
    "parser.add_argument('--c_coef',type=float, default=0.0588, help='c coeficient')\n",
    "parser.add_argument('--d_coef',type=float, default=0.0269, help='d coeficient')\n",
    "args = parser.parse_args(args=[])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "sigma=25/255\n",
    "\n",
    "\n",
    "print(args.input)\n",
    "## Loading Data\n",
    "# No Encoding\n",
    "pos_encode_no = {'type': None}\n",
    "im = utils.normalize(plt.imread(args.input).astype(np.float32), True)\n",
    "im = cv2.resize(im, None, fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)\n",
    "H, W, _ = im.shape\n",
    "# Frequency Encoding\n",
    "pos_encode_freq = {'type':'frequency', 'use_nyquist': True, 'mapping_input': int(max(H, W))}\n",
    "\n",
    "# Gaussian Encoding\n",
    "pos_encode_gaus = {'type':'gaussian', 'scale_B': 10, 'mapping_input': 256}\n",
    "# Create a noisy image using realistic sensor measurement\n",
    "\n",
    "im_noisy = get_noisy_image(im, sigma)\n",
    "im_noisy_gt = utils.normalize(im_noisy, True)[None, ...].astype(np.float32)\n",
    "noise_psnr = ((im_noisy_gt - im)**2).mean().item()\n",
    "noise_psnr = -10*np.log10(noise_psnr)\n",
    "\n",
    "print('Noise PSNR:', noise_psnr,'\\n')\n",
    "print('H:',H, 'W:',W)\n",
    "\n",
    "\n",
    "model_psnr={}\n",
    "model_noise_psnr={}\n",
    "model_ssim={}\n",
    "total_time = {}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/im.png',im[:,:, ::-1]*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create a noisy image using realistic sensor measurement\n",
    "# tau = 9e1 # Photon noise\n",
    "# noise_snr = 2 # Readout noise\n",
    "\n",
    "# sigma=500/255\n",
    "# # im_noisy = utils.measure(im, noise_snr, tau)\n",
    "# im_noisy = get_noisy_image(im, sigma)\n",
    "# im_noisy_gt = utils.normalize(im_noisy, True)[None, ...].astype(np.float32)\n",
    "# noise_psnr = ((im_noisy_gt - im)**2).mean().item()\n",
    "# noise_psnr = -10*np.log10(noise_psnr)\n",
    "\n",
    "# print('Noise PSNR:', noise_psnr,'\\n')\n",
    "# # Plot\n",
    "# im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "\n",
    "# fig, axes = plt.subplots(1, 2, figsize=(10, 10))\n",
    "# axes[0].set_title('Ground Truth')\n",
    "# axes[0].imshow(im)\n",
    "# axes[0].axis('off')\n",
    "# axes[1].set_title('Noisy Image')\n",
    "# axes[1].imshow(im_noisy)\n",
    "# axes[1].axis('off')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "reconstruct_img = torch.tensor(im_noisy).permute(2, 0, 1).unsqueeze(0)\n",
    "mse_array_noisy = ((original_img - reconstruct_img)**2).mean().item()\n",
    "noise_psnr = -10*np.log10(mse_array_noisy)\n",
    "ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "original_img = im\n",
    "reconstruct_img = im_noisy\n",
    "ms_ssim = compare_ssim(im, im_noisy, data_range=1, size_average=False,channel_axis=-1)\n",
    "print('noise_psnr:', noise_psnr)\n",
    "print('noise_ssim:', ms_ssim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InstantNGP\n",
    "class SineLayer(nn.Module):\n",
    "    '''\n",
    "    SineLayer is a custom PyTorch module that applies the Sinusoidal activation function to the output of a linear transformation.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        out_features (int): Number of output features.\n",
    "        bias (bool, optional): If True, the linear transformation includes a bias term. Default is True.\n",
    "        is_first (bool, optional): If it is the first layer, we initialize the weights differently. Default is False.\n",
    "        omega_0 (float, optional): Frequency scaling factor for the sinusoidal activation. Default is 30.\n",
    "        scale (float, optional): Scaling factor for the output of the sine activation. Default is 10.0.\n",
    "        init_weights (bool, optional): If True, initializes the layer's weights according to the SIREN paper. Default is True.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                is_first=False, omega_0=30, scale=10.0, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        # if init_weights:\n",
    "        #     self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # self.linear.bias.data.fill_(10)\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                            1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(1 / self.in_features), \n",
    "                                            np.sqrt(1 / self.in_features))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"\n",
    "        Siren activation\n",
    "        https://arxiv.org/abs/2006.09661\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w0=1):\n",
    "        \"\"\"\n",
    "            w0 comes from the end of section 3\n",
    "            it should be 30 for the first layer\n",
    "            and 1 for the rest\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w0 = torch.tensor(w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(self.w0*(torch.abs(x)+1)*x) \n",
    "        return torch.sin(self.w0 * x) \n",
    "    def extra_repr(self):\n",
    "        return \"w0={}\".format(self.w0)\n",
    "    \n",
    "class PolyReLUCode(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,activate='ReLU',norm_type='None'\n",
    "        ) -> None:\n",
    "        super(PolyReLUCode, self).__init__()\n",
    "        input_dim = 32\n",
    "        hidden_channel=64\n",
    "        \n",
    "        self.positional_encoding = MultiResHashGrid(dim=2,\n",
    "                                                                n_levels = 16,\n",
    "                                                                n_features_per_level = 2,\n",
    "                                                                log2_hashmap_size = 15,\n",
    "                                                                base_resolution = 16,\n",
    "                                                                finest_resolution = 256,\n",
    "                                                            )\n",
    "        w1=100\n",
    "        w2=2\n",
    "        w3=1\n",
    "        w4=1\n",
    "        w5=1\n",
    "        w6=1\n",
    "        self.linear1=SineLayer(input_dim,hidden_channel,omega_0=w1,is_first=True)\n",
    "        if norm_type=='LayerNorm':\n",
    "            self.norm1=nn.LayerNorm(hidden_channel)\n",
    "            self.norm2=nn.LayerNorm(hidden_channel)\n",
    "            self.norm3=nn.LayerNorm(hidden_channel)\n",
    "            self.norm4=nn.LayerNorm(hidden_channel)\n",
    "            self.norm5=nn.LayerNorm(hidden_channel)\n",
    "            self.norm6=nn.LayerNorm(hidden_channel)\n",
    "        elif norm_type=='BatchNorm1d':\n",
    "            self.norm1=nn.BatchNorm1d(65536)\n",
    "            self.norm2=nn.BatchNorm1d(65536)\n",
    "            self.norm3=nn.BatchNorm1d(65536)\n",
    "            self.norm4=nn.BatchNorm1d(65536)\n",
    "        elif norm_type=='None':\n",
    "            self.norm1=nn.Identity()\n",
    "            self.norm2=nn.Identity()\n",
    "            self.norm3=nn.Identity()\n",
    "            \n",
    "        self.linear2=SineLayer(hidden_channel,hidden_channel,omega_0=w2)\n",
    "        # self.linear3=SineLayer(hidden_channel,hidden_channel,omega_0=w3)\n",
    "        if activate=='ReLU':\n",
    "            self.nolinear1=nn.ReLU()\n",
    "            self.nolinear2=nn.ReLU()\n",
    "            self.nolinear3=nn.ReLU()\n",
    "            self.nolinear4=nn.ReLU()\n",
    "            self.nolinear5=nn.ReLU()\n",
    "            self.nolinear6=nn.ReLU()\n",
    "        if activate=='Siren':\n",
    "            self.nolinear1=Siren(w1)\n",
    "            self.nolinear2=Siren(w2)\n",
    "            self.nolinear3=Siren(w3)\n",
    "            self.nolinear4=Siren(w4)\n",
    "            self.nolinear5=Siren(1)\n",
    "            self.nolinear6=Siren(1)\n",
    "        layers = []\n",
    "        layers.append(SineLayer(hidden_channel, 3,is_first=False))\n",
    "        # layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input\n",
    "        x=self.positional_encoding(x)\n",
    "        x = self.nolinear1(self.linear1(x))\n",
    "        x = self.nolinear2(self.linear2(x))\n",
    "        # x = self.nolinear3(self.linear3(x))\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "### InstantNGP\n",
    "args.inr_model='relu'\n",
    "\n",
    "args.lr=5e-3\n",
    "args.scheduler_b=0.1\n",
    "model = PolyReLUCode(activate='ReLU',norm_type='LayerNorm').to(device)\n",
    "\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "    # if step % 1000 == 0:\n",
    "# Plot\n",
    "im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "axes[0].set_title('Ground Truth')\n",
    "axes[0].imshow(im)\n",
    "axes[0].axis('off')\n",
    "axes[1].set_title('Noisy Image')\n",
    "axes[1].imshow(im_noisy)\n",
    "axes[1].axis('off')\n",
    "axes[2].set_title('Denoised')\n",
    "axes[2].imshow(best_img)\n",
    "axes[2].axis('off')\n",
    "plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='InstantNGP'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   Wire\n",
    "### INCODE\n",
    "### Harmonizer Configurations\n",
    "MLP_configs={'task': 'denoising',\n",
    "            'model': 'resnet34',\n",
    "            'truncated_layer':5,\n",
    "            'in_channels': 64,             \n",
    "            'hidden_channels': [32, 16, 8, 4],\n",
    "            'mlp_bias':0.0005,\n",
    "            'activation_layer': nn.SiLU,\n",
    "            'GT': torch.tensor(im_noisy_gt).to(device).permute(0, 3, 1, 2)\n",
    "            }\n",
    "# WIRE\n",
    "### Model Configurations\n",
    "args.inr_model='wire'\n",
    "args.lr= 5e-3\n",
    "args.scheduler_b=0.1\n",
    "model = INR(args.inr_model).run(in_features=2,\n",
    "                                out_features=3, \n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=5.0,\n",
    "                                hidden_omega_0=5.0,\n",
    "                                pos_encode_configs=pos_encode_no\n",
    "                                ).to(device)\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "    # if step % 1000 == 0:\n",
    "# Plot\n",
    "im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "axes[0].set_title('Ground Truth')\n",
    "axes[0].imshow(im)\n",
    "axes[0].axis('off')\n",
    "axes[1].set_title('Noisy Image')\n",
    "axes[1].imshow(im_noisy)\n",
    "axes[1].axis('off')\n",
    "axes[2].set_title('Denoised')\n",
    "axes[2].imshow(best_img)\n",
    "axes[2].axis('off')\n",
    "plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='wire'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INCODE\n",
    "\n",
    "### INCODE\n",
    "### Harmonizer Configurations\n",
    "MLP_configs={'task': 'denoising',\n",
    "            'model': 'resnet34',\n",
    "            'truncated_layer':5,\n",
    "            'in_channels': 64,             \n",
    "            'hidden_channels': [32, 16, 8, 4],\n",
    "            'mlp_bias':0.0005,\n",
    "            'activation_layer': nn.SiLU,\n",
    "            'GT': torch.tensor(im_noisy_gt).to(device).permute(0, 3, 1, 2)\n",
    "            }\n",
    "args.lr= 8e-4\n",
    "args.scheduler_b=0.01\n",
    "### Model Configurations\n",
    "args.inr_model='incode'\n",
    "model = INR(args.inr_model).run(in_features=2,\n",
    "                                out_features=3, \n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=10.0, # Change it from 5 to 20 according to the noise level; higher noise -> lower omega values)\n",
    "                                hidden_omega_0=30.0,\n",
    "                                pos_encode_configs=pos_encode_no, \n",
    "                                MLP_configs = MLP_configs\n",
    "                            ).to(device)\n",
    "\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "# if step % 1000 == 0:\n",
    "# # Plot\n",
    "im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "axes[0].set_title('Ground Truth')\n",
    "axes[0].imshow(im)\n",
    "axes[0].axis('off')\n",
    "axes[1].set_title('Noisy Image')\n",
    "axes[1].imshow(im_noisy)\n",
    "axes[1].axis('off')\n",
    "axes[2].set_title('Denoised')\n",
    "axes[2].imshow(best_img)\n",
    "axes[2].axis('off')\n",
    "plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='incode'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# siren\n",
    "MLP_configs={'task': 'denoising',\n",
    "            'model': 'resnet34',\n",
    "            'truncated_layer':5,\n",
    "            'in_channels': 64,             \n",
    "            'hidden_channels': [32, 16, 8, 4],\n",
    "            'mlp_bias':0.0005,\n",
    "            'activation_layer': nn.SiLU,\n",
    "            'GT': torch.tensor(im_noisy_gt).to(device).permute(0, 3, 1, 2)\n",
    "            }\n",
    "\n",
    "## Model Configurations\n",
    "args.inr_model='siren'\n",
    "args.lr= 1e-3\n",
    "args.scheduler_b=0.1\n",
    "model = INR(args.inr_model).run(in_features=2,\n",
    "                                out_features=3, \n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=30.0,\n",
    "                                hidden_omega_0=30.0,\n",
    "                                pos_encode_configs=pos_encode_no\n",
    "                                ).to(device)\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "    # if step % 1000 == 0:\n",
    "# Plot\n",
    "im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "axes[0].set_title('Ground Truth')\n",
    "axes[0].imshow(im)\n",
    "axes[0].axis('off')\n",
    "axes[1].set_title('Noisy Image')\n",
    "axes[1].imshow(im_noisy)\n",
    "axes[1].axis('off')\n",
    "axes[2].set_title('Denoised')\n",
    "axes[2].imshow(best_img)\n",
    "axes[2].axis('off')\n",
    "plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='siren'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HO_siren\n",
    "\n",
    "class SineLayer(nn.Module):\n",
    "    '''\n",
    "    SineLayer is a custom PyTorch module that applies the Sinusoidal activation function to the output of a linear transformation.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        out_features (int): Number of output features.\n",
    "        bias (bool, optional): If True, the linear transformation includes a bias term. Default is True.\n",
    "        is_first (bool, optional): If it is the first layer, we initialize the weights differently. Default is False.\n",
    "        omega_0 (float, optional): Frequency scaling factor for the sinusoidal activation. Default is 30.\n",
    "        scale (float, optional): Scaling factor for the output of the sine activation. Default is 10.0.\n",
    "        init_weights (bool, optional): If True, initializes the layer's weights according to the SIREN paper. Default is True.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30, scale=10.0, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # self.linear.bias.data.fill_(10)\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)  \n",
    "                # self.linear.bias.data.uniform_(-0.8,0.8)    \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "                # self.linear.bias.data.uniform_(-8,8)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"\n",
    "        Siren activation\n",
    "        https://arxiv.org/abs/2006.09661\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w0=1):\n",
    "        \"\"\"\n",
    "            w0 comes from the end of section 3\n",
    "            it should be 30 for the first layer\n",
    "            and 1 for the rest\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w0 = torch.tensor(w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(self.w0*(torch.abs(x)+1)*x) \n",
    "        return torch.sin(self.w0 * x) \n",
    "    def extra_repr(self):\n",
    "        return \"w0={}\".format(self.w0)\n",
    "        \n",
    "class PolySiren(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,activate='ReLU',norm_type='None'\n",
    "        ) -> None:\n",
    "        super(PolySiren, self).__init__()\n",
    "        input_dim = 2\n",
    "\n",
    "        input_dim = 2 \n",
    "        hidden_channel=256\n",
    "        \n",
    "        \n",
    "        w1=35\n",
    "        w2=1\n",
    "        w3=1\n",
    "        w4=1\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.linear1=SineLayer(input_dim,hidden_channel,omega_0=w1,is_first=True)\n",
    "        if norm_type=='LayerNorm':\n",
    "            self.norm1=nn.LayerNorm(hidden_channel)\n",
    "            self.norm2=nn.LayerNorm(hidden_channel)\n",
    "            self.norm3=nn.LayerNorm(hidden_channel)\n",
    "            self.norm4=nn.LayerNorm(hidden_channel)\n",
    "            self.norm5=nn.LayerNorm(hidden_channel)\n",
    "            self.norm6=nn.LayerNorm(hidden_channel)\n",
    "        elif norm_type=='BatchNorm1d':\n",
    "            self.norm1=nn.BatchNorm1d(65536)\n",
    "            self.norm2=nn.BatchNorm1d(65536)\n",
    "            self.norm3=nn.BatchNorm1d(65536)\n",
    "            self.norm4=nn.BatchNorm1d(65536)\n",
    "        elif norm_type=='None':\n",
    "            self.norm1=nn.Identity()\n",
    "            self.norm2=nn.Identity()\n",
    "            self.norm3=nn.Identity()\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.linear2=SineLayer(hidden_channel,hidden_channel,omega_0=w2)\n",
    "        self.linear3=SineLayer(hidden_channel,hidden_channel,omega_0=w3)\n",
    "        self.linear4=SineLayer(hidden_channel,hidden_channel,omega_0=w4)\n",
    "        # self.linear5=SineLayer(hidden_channel,hidden_channel,omega_0=w3)\n",
    "        # self.linear6=SineLayer(hidden_channel,hidden_channel,omega_0=w4)\n",
    "        if activate=='ReLU':\n",
    "            self.nolinear1=nn.ReLU()\n",
    "            self.nolinear2=nn.ReLU()\n",
    "            self.nolinear3=nn.ReLU()\n",
    "        if activate=='Siren':\n",
    "            self.nolinear1=Siren(w1)\n",
    "            self.nolinear2=Siren(w2)\n",
    "            self.nolinear3=Siren(w3)\n",
    "            self.nolinear4=Siren(w4)\n",
    "            self.nolinear5=Siren(1)\n",
    "            self.nolinear6=Siren(1)\n",
    "        layers = []\n",
    "        layers.append(SineLayer(hidden_channel, 3,is_first=True))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input\n",
    "\n",
    "        \n",
    "        x = self.nolinear1(self.linear1(x))\n",
    "        x = self.nolinear2(self.norm2(x+x*self.linear2(x)))\n",
    "        x = self.nolinear3(self.norm3(x+x*self.linear3(x)))\n",
    "        x = self.nolinear4(self.norm4(x+x*self.linear4(x)))\n",
    "        # x = self.nolinear5(self.norm5(x+x*self.linear5(x)))\n",
    "        # x = self.nolinear6(self.norm6(x+x*self.linear6(x)))\n",
    "        # x = self.nolinear3(x)\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x\n",
    "            \n",
    "\n",
    "args.inr_model = 'siren'\n",
    "args.lr= 2e-3\n",
    "args.scheduler_b=0.1\n",
    "model = PolySiren(activate='Siren',norm_type='LayerNorm').to(device)\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "    # if step % 1000 == 0:\n",
    "    #     # Plot\n",
    "    #     im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "        \n",
    "    #     fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    #     axes[0].set_title('Ground Truth')\n",
    "    #     axes[0].imshow(im)\n",
    "    #     axes[0].axis('off')\n",
    "    #     axes[1].set_title('Noisy Image')\n",
    "    #     axes[1].imshow(im_noisy)\n",
    "    #     axes[1].axis('off')\n",
    "    #     axes[2].set_title('Denoised')\n",
    "    #     axes[2].imshow(best_img)\n",
    "    #     axes[2].axis('off')\n",
    "    #     plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='HO-Siren'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pos.Enc\n",
    "### Model Configurations\n",
    "\n",
    "args.inr_model='relu'\n",
    "args.lr=1e-3\n",
    "args.scheduler_b=0.1\n",
    "model = INR(args.inr_model).run(in_features=2, \n",
    "                                hidden_features=256, \n",
    "                                hidden_layers=3, \n",
    "                                out_features=3,\n",
    "                                outermost_linear=True, \n",
    "                                pos_encode_configs=pos_encode_freq\n",
    "                            ).to(device)\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "    # if step % 1000 == 0:\n",
    "    #     # Plot\n",
    "    #     im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "        \n",
    "    #     fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    #     axes[0].set_title('Ground Truth')\n",
    "    #     axes[0].imshow(im)\n",
    "    #     axes[0].axis('off')\n",
    "    #     axes[1].set_title('Noisy Image')\n",
    "    #     axes[1].imshow(im_noisy)\n",
    "    #     axes[1].axis('off')\n",
    "    #     axes[2].set_title('Denoised')\n",
    "    #     axes[2].imshow(best_img)\n",
    "    #     axes[2].axis('off')\n",
    "    #     plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='Pos.Enc'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HO-Pos.Enc\n",
    "class SineLayer(nn.Module):\n",
    "    '''\n",
    "    SineLayer is a custom PyTorch module that applies the Sinusoidal activation function to the output of a linear transformation.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        out_features (int): Number of output features.\n",
    "        bias (bool, optional): If True, the linear transformation includes a bias term. Default is True.\n",
    "        is_first (bool, optional): If it is the first layer, we initialize the weights differently. Default is False.\n",
    "        omega_0 (float, optional): Frequency scaling factor for the sinusoidal activation. Default is 30.\n",
    "        scale (float, optional): Scaling factor for the output of the sine activation. Default is 10.0.\n",
    "        init_weights (bool, optional): If True, initializes the layer's weights according to the SIREN paper. Default is True.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                is_first=False, omega_0=30, scale=10.0, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # self.linear.bias.data.fill_(10)\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                            1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(1 / self.in_features), \n",
    "                                            np.sqrt(1 / self.in_features))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"\n",
    "        Siren activation\n",
    "        https://arxiv.org/abs/2006.09661\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w0=1):\n",
    "        \"\"\"\n",
    "            w0 comes from the end of section 3\n",
    "            it should be 30 for the first layer\n",
    "            and 1 for the rest\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w0 = torch.tensor(w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(self.w0*(torch.abs(x)+1)*x) \n",
    "        return torch.sin(self.w0 * x) \n",
    "    def extra_repr(self):\n",
    "        return \"w0={}\".format(self.w0)\n",
    "    \n",
    "class PolyReLUCode(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,activate='ReLU',norm_type='None'\n",
    "        ) -> None:\n",
    "        super(PolyReLUCode, self).__init__()\n",
    "        input_dim = 2\n",
    "\n",
    "        input_dim = 26\n",
    "        hidden_channel=256\n",
    "        \n",
    "        self.positional_encoding = Encoding('gaussian').run(in_features=2, pos_encode_configs=pos_encode_gaus)\n",
    "        self.positional_encoding = Encoding('frequency').run(in_features=2, pos_encode_configs=pos_encode_freq)\n",
    "        w1=50\n",
    "        w2=2\n",
    "        w3=2\n",
    "        w4=2\n",
    "        w5=1\n",
    "        w6=1\n",
    "        self.linear1=SineLayer(input_dim,hidden_channel,omega_0=w1,is_first=True)\n",
    "        if norm_type=='LayerNorm':\n",
    "            self.norm1=nn.LayerNorm(hidden_channel)\n",
    "            self.norm2=nn.LayerNorm(hidden_channel)\n",
    "            self.norm3=nn.LayerNorm(hidden_channel)\n",
    "            self.norm4=nn.LayerNorm(hidden_channel)\n",
    "            self.norm5=nn.LayerNorm(hidden_channel)\n",
    "            self.norm6=nn.LayerNorm(hidden_channel)\n",
    "        elif norm_type=='BatchNorm1d':\n",
    "            self.norm1=nn.BatchNorm1d(65536)\n",
    "            self.norm2=nn.BatchNorm1d(65536)\n",
    "            self.norm3=nn.BatchNorm1d(65536)\n",
    "            self.norm4=nn.BatchNorm1d(65536)\n",
    "        elif norm_type=='None':\n",
    "            self.norm1=nn.Identity()\n",
    "            self.norm2=nn.Identity()\n",
    "            self.norm3=nn.Identity()\n",
    "            \n",
    "        self.linear2=SineLayer(hidden_channel,hidden_channel,omega_0=w2)\n",
    "        self.linear3=SineLayer(hidden_channel,hidden_channel,omega_0=w3)\n",
    "        self.linear4=SineLayer(hidden_channel,hidden_channel,omega_0=w4)\n",
    "        # self.linear5=SineLayer(hidden_channel,hidden_channel,omega_0=w3)\n",
    "        # self.linear6=SineLayer(hidden_channel,hidden_channel,omega_0=w4)\n",
    "        if activate=='ReLU':\n",
    "            self.nolinear1=nn.ReLU()\n",
    "            self.nolinear2=nn.ReLU()\n",
    "            self.nolinear3=nn.ReLU()\n",
    "            self.nolinear4=nn.ReLU()\n",
    "            self.nolinear5=nn.ReLU()\n",
    "            self.nolinear6=nn.ReLU()\n",
    "        if activate=='Siren':\n",
    "            self.nolinear1=Siren(w1)\n",
    "            self.nolinear2=Siren(w2)\n",
    "            self.nolinear3=Siren(w3)\n",
    "            self.nolinear4=Siren(w4)\n",
    "            self.nolinear5=Siren(1)\n",
    "            self.nolinear6=Siren(1)\n",
    "        layers = []\n",
    "        layers.append(SineLayer(hidden_channel, 3,is_first=True))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input\n",
    "        x=self.positional_encoding(x)\n",
    "        x = self.nolinear1(self.linear1(x))\n",
    "        x = self.nolinear2(self.norm2(x+x*self.linear2(x)))\n",
    "        x = self.nolinear3(self.norm3(x+x*self.linear3(x)))\n",
    "        x = self.nolinear4(self.norm4(x+x*self.linear4(x)))\n",
    "        # x = self.nolinear5(self.norm3(x+x*self.linear5(x)))\n",
    "        # x = self.nolinear6(self.norm4(x+x*self.linear6(x)))\n",
    "\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x\n",
    "            \n",
    "  \n",
    "\n",
    "args.inr_model='relu'\n",
    "args.lr= 8e-3\n",
    "args.scheduler_b=0.01\n",
    "model = PolyReLUCode(activate='ReLU',norm_type='LayerNorm').to(device)\n",
    "\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "    # if step % 1000 == 0:\n",
    "# Plot\n",
    "im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "axes[0].set_title('Ground Truth')\n",
    "axes[0].imshow(im)\n",
    "axes[0].axis('off')\n",
    "axes[1].set_title('Noisy Image')\n",
    "axes[1].imshow(im_noisy)\n",
    "axes[1].axis('off')\n",
    "axes[2].set_title('Denoised')\n",
    "axes[2].imshow(best_img)\n",
    "axes[2].axis('off')\n",
    "plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='HO-Pos.Enc'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFN\n",
    "args.inr_model='relu'\n",
    "args.lr=1.2e-3\n",
    "args.scheduler_b=0.1\n",
    "model = INR(args.inr_model).run(in_features=2, \n",
    "                                hidden_features=256, \n",
    "                                hidden_layers=3, \n",
    "                                out_features=3,\n",
    "                                outermost_linear=True, \n",
    "                                pos_encode_configs=pos_encode_gaus\n",
    "                            ).to(device)\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "    # if step % 1000 == 0:\n",
    "    #     # Plot\n",
    "    #     im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "        \n",
    "    #     fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    #     axes[0].set_title('Ground Truth')\n",
    "    #     axes[0].imshow(im)\n",
    "    #     axes[0].axis('off')\n",
    "    #     axes[1].set_title('Noisy Image')\n",
    "    #     axes[1].imshow(im_noisy)\n",
    "    #     axes[1].axis('off')\n",
    "    #     axes[2].set_title('Denoised')\n",
    "    #     axes[2].imshow(best_img)\n",
    "    #     axes[2].axis('off')\n",
    "    #     plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='FFN'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HO-FFN\n",
    "class SineLayer(nn.Module):\n",
    "    '''\n",
    "    SineLayer is a custom PyTorch module that applies the Sinusoidal activation function to the output of a linear transformation.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        out_features (int): Number of output features.\n",
    "        bias (bool, optional): If True, the linear transformation includes a bias term. Default is True.\n",
    "        is_first (bool, optional): If it is the first layer, we initialize the weights differently. Default is False.\n",
    "        omega_0 (float, optional): Frequency scaling factor for the sinusoidal activation. Default is 30.\n",
    "        scale (float, optional): Scaling factor for the output of the sine activation. Default is 10.0.\n",
    "        init_weights (bool, optional): If True, initializes the layer's weights according to the SIREN paper. Default is True.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                is_first=False, omega_0=30, scale=10.0, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # self.linear.bias.data.fill_(10)\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                            1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(1 / self.in_features), \n",
    "                                            np.sqrt(1 / self.in_features))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"\n",
    "        Siren activation\n",
    "        https://arxiv.org/abs/2006.09661\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w0=1):\n",
    "        \"\"\"\n",
    "            w0 comes from the end of section 3\n",
    "            it should be 30 for the first layer\n",
    "            and 1 for the rest\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w0 = torch.tensor(w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(self.w0*(torch.abs(x)+1)*x) \n",
    "        return torch.sin(self.w0 * x) \n",
    "    def extra_repr(self):\n",
    "        return \"w0={}\".format(self.w0)\n",
    "    \n",
    "class PolyReLUCode(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,activate='ReLU',norm_type='None'\n",
    "        ) -> None:\n",
    "        super(PolyReLUCode, self).__init__()\n",
    "        input_dim = 2\n",
    "\n",
    "        input_dim = 512\n",
    "        hidden_channel=256\n",
    "        \n",
    "        self.positional_encoding = Encoding('gaussian').run(in_features=2, pos_encode_configs=pos_encode_gaus)\n",
    "        # self.positional_encoding = Encoding('frequency').run(in_features=2, pos_encode_configs=pos_encode_freq)\n",
    "        w1=50\n",
    "        w2=2\n",
    "        w3=2\n",
    "        w4=2\n",
    "        w5=1\n",
    "        w6=1\n",
    "        self.linear1=SineLayer(input_dim,hidden_channel,omega_0=w1,is_first=True)\n",
    "        if norm_type=='LayerNorm':\n",
    "            self.norm1=nn.LayerNorm(hidden_channel)\n",
    "            self.norm2=nn.LayerNorm(hidden_channel)\n",
    "            self.norm3=nn.LayerNorm(hidden_channel)\n",
    "            self.norm4=nn.LayerNorm(hidden_channel)\n",
    "            self.norm5=nn.LayerNorm(hidden_channel)\n",
    "            self.norm6=nn.LayerNorm(hidden_channel)\n",
    "        elif norm_type=='BatchNorm1d':\n",
    "            self.norm1=nn.BatchNorm1d(65536)\n",
    "            self.norm2=nn.BatchNorm1d(65536)\n",
    "            self.norm3=nn.BatchNorm1d(65536)\n",
    "            self.norm4=nn.BatchNorm1d(65536)\n",
    "        elif norm_type=='None':\n",
    "            self.norm1=nn.Identity()\n",
    "            self.norm2=nn.Identity()\n",
    "            self.norm3=nn.Identity()\n",
    "            \n",
    "        self.linear2=SineLayer(hidden_channel,hidden_channel,omega_0=w2)\n",
    "        self.linear3=SineLayer(hidden_channel,hidden_channel,omega_0=w3)\n",
    "        self.linear4=SineLayer(hidden_channel,hidden_channel,omega_0=w4)\n",
    "        # self.linear5=SineLayer(hidden_channel,hidden_channel,omega_0=w3)\n",
    "        # self.linear6=SineLayer(hidden_channel,hidden_channel,omega_0=w4)\n",
    "        if activate=='ReLU':\n",
    "            self.nolinear1=nn.ReLU()\n",
    "            self.nolinear2=nn.ReLU()\n",
    "            self.nolinear3=nn.ReLU()\n",
    "            self.nolinear4=nn.ReLU()\n",
    "            self.nolinear5=nn.ReLU()\n",
    "            self.nolinear6=nn.ReLU()\n",
    "        if activate=='Siren':\n",
    "            self.nolinear1=Siren(w1)\n",
    "            self.nolinear2=Siren(w2)\n",
    "            self.nolinear3=Siren(w3)\n",
    "            self.nolinear4=Siren(w4)\n",
    "            self.nolinear5=Siren(1)\n",
    "            self.nolinear6=Siren(1)\n",
    "        layers = []\n",
    "        layers.append(SineLayer(hidden_channel, 3,is_first=True))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input\n",
    "        x=self.positional_encoding(x)\n",
    "        x = self.nolinear1(self.linear1(x))\n",
    "        x = self.nolinear2(self.norm2(x+x*self.linear2(x)))\n",
    "        x = self.nolinear3(self.norm3(x+x*self.linear3(x)))\n",
    "        x = self.nolinear4(self.norm4(x+x*self.linear4(x)))\n",
    "        # x = self.nolinear5(self.norm3(x+x*self.linear5(x)))\n",
    "        # x = self.nolinear6(self.norm4(x+x*self.linear6(x)))\n",
    "\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x\n",
    "            \n",
    "\n",
    "args.inr_model='relu'\n",
    "args.lr= 7e-3\n",
    "args.scheduler_b=0.01\n",
    "model = PolyReLUCode(activate='ReLU',norm_type='LayerNorm').to(device)\n",
    "\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "mse_array_noisy = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).cuda().reshape(H * W, 3)[None, ...]\n",
    "gt_noisy = torch.tensor(im_noisy).cuda().reshape(H*W, 3)[None, ...]\n",
    "\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "psnr_values = []\n",
    "noise_psnr_values=[]\n",
    "ssim_values = []\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].cuda()\n",
    "        b_indices = b_indices.cuda()\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt_noisy[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate and log mean squared error (MSE) and PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array_noisy[step] = ((gt_noisy - rec)**2).mean().item()\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        noise_psnr = -10*torch.log10(mse_array_noisy[step])\n",
    "        noise_psnr_values.append(noise_psnr.item())\n",
    "        psnr_values.append(psnr.item())\n",
    "        \n",
    "        \n",
    "    # Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's MSE is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | Truth PSNR: {:.4f} | Noise PSNR: {:.4f}\".format(step, \n",
    "                                                                    mse_array_noisy[step].item(),\n",
    "                                                                    psnr.item(),noise_psnr.item())) \n",
    "    # if step % 1000 == 0:\n",
    "    #     # Plot\n",
    "    #     im_noisy = (im_noisy - im_noisy.min()) / (im_noisy.max() - im_noisy.min())\n",
    "        \n",
    "    #     fig, axes = plt.subplots(1, 3, figsize=(10, 10))\n",
    "    #     axes[0].set_title('Ground Truth')\n",
    "    #     axes[0].imshow(im)\n",
    "    #     axes[0].axis('off')\n",
    "    #     axes[1].set_title('Noisy Image')\n",
    "    #     axes[1].imshow(im_noisy)\n",
    "    #     axes[1].axis('off')\n",
    "    #     axes[2].set_title('Denoised')\n",
    "    #     axes[2].imshow(best_img)\n",
    "    #     axes[2].axis('off')\n",
    "    #     plt.show()\n",
    "\n",
    "        \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='HO-FFN'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "model_noise_psnr[args.inr_model]=noise_psnr_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png',im_noisy[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "tmax=0.15\n",
    "plt.style.use('default')\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result/image_denoise/im_noisy.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=tmax)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result/image_denoise/'+args.inr_model+'_best_img_inferno.png'\n",
    "fig = plt.figure()\n",
    "plt.imshow(gray_difference, cmap='inferno',vmin=0,vmax=tmax)\n",
    "plt.axis('off')\n",
    "# plt.savefig(best_img_save_name,format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    weights = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, weights, mode='valid')\n",
    "font = {'font': 'Times New Roman', 'size': 14}\n",
    "plt.style.use('default')\n",
    "fig = plt.figure(figsize=(15.0/2.54, 12/2.54))\n",
    "axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 11}\n",
    "plt.rc('font', **axfont)\n",
    "for i, model_name in enumerate(model_psnr):\n",
    "    psnr_num=model_psnr[model_name]\n",
    "    psnr_num=moving_average(psnr_num,20)\n",
    "    plt.plot(np.arange(len(psnr_num[:-1])), psnr_num[:-1], linewidth=1.5,label = f\"{(model_name).upper()}\")\n",
    "\n",
    "plt.xlabel('# Epoch', fontdict=font)\n",
    "plt.ylabel('PSNR (dB)', fontdict=font)\n",
    "plt.ylim(16,30.5)\n",
    "plt.title('Image Representation', fontdict={'family': 'Times New Roman', 'size': 14, 'weight': 'bold'})\n",
    "plt.legend(fancybox=True, shadow=True, ncol=2)\n",
    "plt.grid(True, color='lightgray')\n",
    "plt.tight_layout()  # 调整整体布局\n",
    "plt.savefig(\"/root/autodl-tmp/INCODE-main/result/image_denoise/psnr.png\",format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'font': 'Times New Roman', 'size': 14}\n",
    "plt.style.use('default')\n",
    "fig = plt.figure(figsize=(15.0/2.54, 12/2.54))\n",
    "axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 11}\n",
    "plt.rc('font', **axfont)\n",
    "for i, model_name in enumerate(model_psnr):\n",
    "    psnr_num=model_noise_psnr[model_name]\n",
    "    # psnr_num=moving_average(psnr_num,3)\n",
    "    plt.plot(np.arange(len(psnr_num[:-1])), psnr_num[:-1], linewidth=1.5,label = f\"{(model_name).upper()}\")\n",
    "\n",
    "plt.xlabel('# Epoch', fontdict=font)\n",
    "plt.ylabel('PSNR (dB)', fontdict=font)\n",
    "# plt.ylim(12,34)\n",
    "plt.title('Noise Image Representation', fontdict={'family': 'Times New Roman', 'size': 14, 'weight': 'bold'})\n",
    "plt.legend(fancybox=True, shadow=True, ncol=2)\n",
    "plt.grid(True, color='lightgray')\n",
    "plt.tight_layout()  # 调整整体布局\n",
    "# plt.savefig(\"/root/autodl-tmp/INCODE-main/result/image_denoise/psnr.png\",format='png',dpi=2000,bbox_inches='tight', pad_inches=0)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# from scipy.interpolate import interp1d\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# custom_colors = [('#008F00', '#008F00'), ('#B93DAF', '#B93DAF'), ('#009EFA', '#009EFA'), ('#F30000', '#F30000'),   ('#000000', '#000000'), ('#808000', '#808000'), ('#FFFF00', '#FFFF00'), ('#7F00FF', '#7F00FF'), ('#FF7F50', '#FF7F50')]  # Pair of colors for noise and clean data\n",
    "# font = {'font': 'Times New Roman', 'size': 14}#008B74\n",
    "# plt.style.use('default')\n",
    "# plt.figure(figsize=(18.0/2.54, 10/2.54))\n",
    "# axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 10}\n",
    "# plt.rc('font', **axfont)\n",
    "# for i, model_name in enumerate(model_psnr):\n",
    "#     psnr_num = model_psnr[model_name]\n",
    "#     noise_psnr_num = model_noise_psnr[model_name]\n",
    "#     noise_color, clean_color = custom_colors[i]\n",
    "#     # 移动平均\n",
    "#     x=np.arange(len(psnr_num[:-1]))\n",
    "#     y=psnr_num[:-1]\n",
    "#     window_size = 5\n",
    "#     y_rolling = pd.Series(psnr_num).rolling(window=window_size).mean()\n",
    "#     # 样条插值\n",
    "#     x_dense = np.linspace(0, 2000, 10000)  # 更密集的x值用于插值\n",
    "#     spl = interp1d(x, y, kind='cubic')\n",
    "#     y_spline = spl(x_dense)\n",
    "\n",
    "#     # plt.plot(np.arange(len(noise_psnr_num[:-1])), noise_psnr_num[:-1], linestyle='--', linewidth=2,color=noise_color, label=f\"{model_name.upper()} NOISE\")\n",
    "#     plt.plot(x_dense, y_spline, linestyle='-', color=clean_color, linewidth=2, label=f\"{model_name.upper()} CLEAN\")\n",
    "\n",
    "# plt.xlabel('Epoch', fontdict=font)\n",
    "# plt.ylabel('PSNR (dB)', fontdict=font)\n",
    "# # plt.ylim(15,27)\n",
    "# plt.ylim(21,26)\n",
    "# plt.title('Image Denoise', fontdict={'family': 'Times New Roman', 'size': 16, 'weight': 'bold'})\n",
    "# plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=3)\n",
    "# # plt.legend(fancybox=True, shadow=True, ncol=2)\n",
    "# plt.grid(False, color='lightgray')\n",
    "# # plt.savefig('/home/wrt/Poly/INCODE-main/result/result5.pdf',format='pdf',dpi=2000, bbox_inches='tight')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    weights = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, weights, mode='valid')\n",
    "\n",
    "custom_colors = [('#008F00', '#008F00'), ('#B93DAF', '#B93DAF'), ('#009EFA', '#009EFA'), ('#F30000', '#F30000'),   ('#000000', '#000000'), ('#808000', '#808000'), ('#8A9A5B', '#8A9A5B'), ('#7F00FF', '#7F00FF'), ('#FF7F50', '#FF7F50')]  # Pair of colors for noise and clean data\n",
    "font = {'font': 'Times New Roman', 'size': 14}#008B74\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(18.0/2.54, 10/2.54))\n",
    "axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 10}\n",
    "plt.rc('font', **axfont)\n",
    "for i, model_name in enumerate(model_psnr):\n",
    "    psnr_num = model_psnr[model_name]\n",
    "    noise_psnr_num = model_noise_psnr[model_name]\n",
    "    noise_color, clean_color = custom_colors[i]\n",
    "    psnr_num=moving_average(psnr_num,20)\n",
    "    # plt.plot(np.arange(len(noise_psnr_num[:-1])), noise_psnr_num[:-1], linestyle='--', linewidth=2,color=noise_color, label=f\"{model_name.upper()} NOISE\")\n",
    "    plt.plot(np.arange(len(psnr_num[:-1])), psnr_num[:-1], linestyle='-', color=clean_color, linewidth=2, label=f\"{model_name.upper()} CLEAN\")\n",
    "\n",
    "plt.xlabel('Epoch', fontdict=font)\n",
    "plt.ylabel('PSNR (dB)', fontdict=font)\n",
    "# plt.ylim(15,27)\n",
    "plt.ylim(20,31)\n",
    "plt.title('Image Denoise', fontdict={'family': 'Times New Roman', 'size': 16, 'weight': 'bold'})\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=3)\n",
    "# plt.legend(fancybox=True, shadow=True, ncol=2)\n",
    "plt.grid(False, color='lightgray')\n",
    "plt.savefig('/root/autodl-tmp/INCODE-main/result/image_denoise/result5.pdf',format='pdf',dpi=2000, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(data, window_size):\n",
    "    weights = np.ones(window_size) / window_size\n",
    "    return np.convolve(data, weights, mode='valid')\n",
    "\n",
    "custom_colors = [('#008F00', '#008F00'), ('#B93DAF', '#B93DAF'), ('#009EFA', '#009EFA'), ('#F30000', '#F30000'),   ('#000000', '#000000'), ('#808000', '#808000'), ('#8A9A5B', '#8A9A5B'), ('#7F00FF', '#7F00FF'), ('#FF7F50', '#FF7F50')]  # Pair of colors for noise and clean data\n",
    "font = {'font': 'Times New Roman', 'size': 14}#008B74\n",
    "plt.style.use('default')\n",
    "plt.figure(figsize=(18.0/2.54, 10/2.54))\n",
    "axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 10}\n",
    "plt.rc('font', **axfont)\n",
    "for i, model_name in enumerate(model_psnr):\n",
    "    psnr_num = model_psnr[model_name]\n",
    "    noise_psnr_num = model_noise_psnr[model_name]\n",
    "    noise_color, clean_color = custom_colors[i]\n",
    "    psnr_num=moving_average(psnr_num,20)\n",
    "    plt.plot(np.arange(len(noise_psnr_num[:-1])), noise_psnr_num[:-1], linestyle='--', linewidth=2,color=noise_color, label=f\"{model_name.upper()} NOISE\")\n",
    "    # plt.plot(np.arange(len(psnr_num[:-1])), psnr_num[:-1], linestyle='-', color=clean_color, linewidth=2, label=f\"{model_name.upper()} CLEAN\")\n",
    "\n",
    "plt.xlabel('Epoch', fontdict=font)\n",
    "plt.ylabel('PSNR (dB)', fontdict=font)\n",
    "# plt.ylim(15,27)\n",
    "plt.ylim(19,27)\n",
    "plt.title('Image Denoise', fontdict={'family': 'Times New Roman', 'size': 16, 'weight': 'bold'})\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.15), fancybox=True, shadow=False, ncol=3)\n",
    "# plt.legend(fancybox=True, shadow=True, ncol=2)\n",
    "plt.grid(False, color='lightgray')\n",
    "plt.savefig('/root/autodl-tmp/INCODE-main/result/image_denoise/result6.pdf',format='pdf',dpi=2000, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 生成随机数据\n",
    "x = np.linspace(-2 * np.pi, 2 * np.pi, 100)\n",
    "y = np.sin(x) + np.random.randn(100) * 0.2\n",
    "\n",
    "# 计算Loess曲线\n",
    "lowess = sm.nonparametric.lowess(y, x, frac=0.3)\n",
    "\n",
    "# 绘制原始数据和平滑曲线\n",
    "plt.scatter(x, y, label='Original Data')\n",
    "plt.plot(lowess[:, 0], lowess[:, 1], c='r', label='Loess Smoothed')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
