{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "from scipy import io\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from pytorch_msssim import ssim\n",
    "from skimage.metrics import structural_similarity as compare_ssim\n",
    "from modules import utils\n",
    "from modules.models import INR\n",
    "\n",
    "from torchsummary import summary\n",
    "from modules.encoding import Encoding\n",
    "import time\n",
    "from encoding import MultiResHashGrid\n",
    "import torch\n",
    "import lpips\n",
    "from pytorch_msssim import ssim\n",
    "\n",
    "lpips_vgg_model = lpips.LPIPS(net=\"vgg\")\n",
    "lpips_alex_model = lpips.LPIPS(net=\"alex\")\n",
    "\n",
    "parser = argparse.ArgumentParser(description='INCODE')\n",
    "# Shared Parameters\n",
    "parser.add_argument('--input',type=str, default='/root/autodl-tmp/INCODE-main/0070.png', help='Input image path')\n",
    "# parser.add_argument('--input',type=str, default='/home/cy/Poly/INCODE-main/middle.png', help='Input image path')\n",
    "parser.add_argument('--inr_model',type=str, default='siren', help='[gauss, mfn, relu, siren, wire, wire2d, ffn, incode]')\n",
    "parser.add_argument('--ffn_type',type=str, default='siren', help='[relu, siren, swish]')\n",
    "parser.add_argument('--lr',type=float, default=5e-3, help='Learning rate')\n",
    "parser.add_argument('--using_schedular', type=bool, default=True, help='Whether to use schedular')\n",
    "parser.add_argument('--scheduler_b', type=float, default=0.1, help='Learning rate scheduler')\n",
    "parser.add_argument('--maxpoints', type=int, default=128*128, help='Batch size')\n",
    "parser.add_argument('--niters', type=int, default=101, help='Number if iterations')\n",
    "parser.add_argument('--steps_til_summary', type=int, default=10, help='Number of steps till summary visualization')\n",
    "\n",
    "# INCODE Parameters\n",
    "parser.add_argument('--a_coef',type=float, default=0.1993, help='a coeficient')\n",
    "parser.add_argument('--b_coef',type=float, default=0.0196, help='b coeficient')\n",
    "parser.add_argument('--c_coef',type=float, default=0.0588, help='c coeficient')\n",
    "parser.add_argument('--d_coef',type=float, default=0.0269, help='d coeficient')\n",
    "parser.add_argument('--using_cosoptim', type=bool, default=False, help='Whether to use schedular')\n",
    "parser.add_argument('--eta_min',type=float, default=1e-8, help='d coeficient')\n",
    "parser.add_argument('--T_max',type=float, default=5001, help='d coeficient')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(args.input)\n",
    "## Loading Data\n",
    "im = utils.normalize(plt.imread(args.input).astype(np.float32), True)\n",
    "# im=cv2.resize(im, None, fx=1024/im.shape[1], fy=1024/im.shape[0], interpolation=cv2.INTER_AREA)\n",
    "im = cv2.resize(im, None, fx=1/4, fy=1/4, interpolation=cv2.INTER_AREA)\n",
    "H, W, _ = im.shape\n",
    "print('H:',H, 'W:',W)\n",
    "steps=250\n",
    "per_epoch=int((H*W)/args.maxpoints)\n",
    "# args.niters=int(steps/per_epoch)\n",
    "print('per_epoch:',per_epoch,'args.niters:',args.niters)\n",
    "# Frequency Encoding\n",
    "pos_encode_freq = {'type':'frequency', 'use_nyquist': True, 'mapping_input': int(max(H, W)/3)}\n",
    "\n",
    "# Gaussian Encoding\n",
    "pos_encode_gaus = {'type':'gaussian', 'scale_B': 10, 'mapping_input': 256}\n",
    "\n",
    "# No Encoding\n",
    "pos_encode_no = {'type': None}\n",
    "\n",
    "model_psnr={}\n",
    "model_ssim={}\n",
    "total_time = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# relu+hash\n",
    "class SineLayer(nn.Module):\n",
    "    '''\n",
    "    SineLayer is a custom PyTorch module that applies the Sinusoidal activation function to the output of a linear transformation.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        out_features (int): Number of output features.\n",
    "        bias (bool, optional): If True, the linear transformation includes a bias term. Default is True.\n",
    "        is_first (bool, optional): If it is the first layer, we initialize the weights differently. Default is False.\n",
    "        omega_0 (float, optional): Frequency scaling factor for the sinusoidal activation. Default is 30.\n",
    "        scale (float, optional): Scaling factor for the output of the sine activation. Default is 10.0.\n",
    "        init_weights (bool, optional): If True, initializes the layer's weights according to the SIREN paper. Default is True.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                is_first=False, omega_0=30, scale=10.0, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        # if init_weights:\n",
    "        #     self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # self.linear.bias.data.fill_(10)\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                            1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(1 / self.in_features), \n",
    "                                            np.sqrt(1 / self.in_features))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"\n",
    "        Siren activation\n",
    "        https://arxiv.org/abs/2006.09661\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w0=1):\n",
    "        \"\"\"\n",
    "            w0 comes from the end of section 3\n",
    "            it should be 30 for the first layer\n",
    "            and 1 for the rest\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w0 = torch.tensor(w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(self.w0*(torch.abs(x)+1)*x) \n",
    "        return torch.sin(self.w0 * x) \n",
    "    def extra_repr(self):\n",
    "        return \"w0={}\".format(self.w0)\n",
    "    \n",
    "class PolyReLUCode(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,activate='ReLU',norm_type='None'\n",
    "        ) -> None:\n",
    "        super(PolyReLUCode, self).__init__()\n",
    "        input_dim = 32\n",
    "        hidden_channel=64\n",
    "        \n",
    "        self.positional_encoding = MultiResHashGrid(dim=2,\n",
    "                                                                n_levels = 16,\n",
    "                                                                n_features_per_level = 2,\n",
    "                                                                log2_hashmap_size = 14,\n",
    "                                                                base_resolution = 16,\n",
    "                                                                finest_resolution = 256,\n",
    "                                                            )\n",
    "        w1=100\n",
    "        w2=2\n",
    "        w3=1\n",
    "        w4=1\n",
    "        w5=1\n",
    "        w6=1\n",
    "        self.linear1=SineLayer(input_dim,hidden_channel,omega_0=w1,is_first=True)\n",
    "        if norm_type=='LayerNorm':\n",
    "            self.norm1=nn.LayerNorm(hidden_channel)\n",
    "            self.norm2=nn.LayerNorm(hidden_channel)\n",
    "            self.norm3=nn.LayerNorm(hidden_channel)\n",
    "            self.norm4=nn.LayerNorm(hidden_channel)\n",
    "            self.norm5=nn.LayerNorm(hidden_channel)\n",
    "            self.norm6=nn.LayerNorm(hidden_channel)\n",
    "        elif norm_type=='BatchNorm1d':\n",
    "            self.norm1=nn.BatchNorm1d(65536)\n",
    "            self.norm2=nn.BatchNorm1d(65536)\n",
    "            self.norm3=nn.BatchNorm1d(65536)\n",
    "            self.norm4=nn.BatchNorm1d(65536)\n",
    "        elif norm_type=='None':\n",
    "            self.norm1=nn.Identity()\n",
    "            self.norm2=nn.Identity()\n",
    "            self.norm3=nn.Identity()\n",
    "            \n",
    "        self.linear2=SineLayer(hidden_channel,hidden_channel,omega_0=w2)\n",
    "        if activate=='ReLU':\n",
    "            self.nolinear1=nn.ReLU()\n",
    "            self.nolinear2=nn.ReLU()\n",
    "            self.nolinear3=nn.ReLU()\n",
    "            self.nolinear4=nn.ReLU()\n",
    "            self.nolinear5=nn.ReLU()\n",
    "            self.nolinear6=nn.ReLU()\n",
    "        if activate=='Siren':\n",
    "            self.nolinear1=Siren(w1)\n",
    "            self.nolinear2=Siren(w2)\n",
    "            self.nolinear3=Siren(w3)\n",
    "            self.nolinear4=Siren(w4)\n",
    "            self.nolinear5=Siren(1)\n",
    "            self.nolinear6=Siren(1)\n",
    "        layers = []\n",
    "        layers.append(SineLayer(hidden_channel, 3,is_first=True))\n",
    "        # layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input\n",
    "        x=self.positional_encoding(x)\n",
    "        x = self.nolinear1(self.linear1(x))\n",
    "        x = self.nolinear2(self.linear2(x))\n",
    "\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "args.inr_model='relu'\n",
    "\n",
    "args.lr=5e-3\n",
    "model = PolyReLUCode(activate='ReLU',norm_type='LayerNorm').to(device)\n",
    "\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "    \n",
    "if args.using_cosoptim:\n",
    "    optim = torch.optim.Adam(params=model.parameters(), lr=args.lr, betas=(0.9, 0.99), eps=1e-15, weight_decay=0)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer = optim,T_max = args.T_max,eta_min=args.eta_min)\n",
    "else:\n",
    "    optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "    scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "\n",
    "# torch.optim.lr_scheduler.StepLR(optim, step_size  = step, gamma = 0.8)\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).reshape(H * W, 3)[None, ...].to(device)\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        # print(optim.param_groups[0]['lr'])\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].to(device)\n",
    "        b_indices = b_indices.to(device)\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            # print(b_coords.size())\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        psnr_values.append(psnr.item())\n",
    "\n",
    "    #Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        if args.inr_model == 'incode' and 30 < step:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's loss is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "        \n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | PSNR: {:.4f} | SSIM:{:.4f}\".format(step, \n",
    "                                                                    mse_array[step].item(),\n",
    "                                                                    psnr.item(),ms_ssim.item()))\n",
    "        \n",
    "        # Plot\n",
    "        # fig, axes = plt.subplots(1, 3, figsize=(12, 12))\n",
    "        # axes[0].set_title('Ground Truth')\n",
    "        # axes[0].imshow(im)\n",
    "        # axes[0].axis('off')\n",
    "        # axes[1].set_title('Reconstructed')\n",
    "        # axes[1].imshow(best_img)\n",
    "        # axes[1].axis('off')\n",
    "        # axes[2].set_title('error')\n",
    "        # axes[2].imshow((im-best_img))\n",
    "        # axes[2].axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "args.inr_model='Hash_relu'\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())\n",
    "print('----------------------------------\\n\\n')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result//'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result//im.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=0.1)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wire\n",
    "### Model Configurations\n",
    "\n",
    "args.inr_model='wire'\n",
    "args.lr= 2e-3\n",
    "model = INR(args.inr_model).run(in_features=2, \n",
    "                                hidden_features=370, \n",
    "                                hidden_layers=3, \n",
    "                                out_features=3, \n",
    "                                wire_type='complex',\n",
    "                                outermost_linear=True, \n",
    "                                first_omega_0=20, \n",
    "                                hidden_omega_0=20, \n",
    "                                sigma=30.0,\n",
    "                                pos_encode_configs=pos_encode_no\n",
    "                            ).to(device)\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "# if args.inr_model == 'wire':\n",
    "#     args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "    \n",
    "if args.using_cosoptim:\n",
    "    optim = torch.optim.Adam(params=model.parameters(), lr=args.lr, betas=(0.9, 0.99), eps=1e-15, weight_decay=0)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer = optim,T_max = args.T_max,eta_min=args.eta_min)\n",
    "else:\n",
    "    optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "    scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "# torch.optim.lr_scheduler.StepLR(optim, step_size  = step, gamma = 0.8)\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).reshape(H * W, 3)[None, ...].to(device)\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        # print(optim.param_groups[0]['lr'])\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].to(device)\n",
    "        b_indices = b_indices.to(device)\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            # print(b_coords.size())\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        psnr_values.append(psnr.item())\n",
    "\n",
    "    #Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        if args.inr_model == 'incode' and 30 < step:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's loss is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "        \n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | PSNR: {:.4f} | SSIM:{:.4f}\".format(step, \n",
    "                                                                    mse_array[step].item(),\n",
    "                                                                    psnr.item(),ms_ssim.item()))\n",
    "        \n",
    "        # # Plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(12, 12))\n",
    "        # axes[0].set_title('Ground Truth')\n",
    "        # axes[0].imshow(im)\n",
    "        # axes[0].axis('off')\n",
    "        # axes[1].set_title('Reconstructed')\n",
    "        # axes[1].imshow(best_img)\n",
    "        # axes[1].axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())\n",
    "args.inr_model='wire'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())\n",
    "print('----------------------------------\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result//'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result//im.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=0.1)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#siren\n",
    "### Model Configurations\n",
    "args.inr_model='siren'\n",
    "args.lr= 1e-3\n",
    "model = INR(args.inr_model).run(in_features=2,\n",
    "                                out_features=3, \n",
    "                                hidden_features=256,\n",
    "                                hidden_layers=3,\n",
    "                                first_omega_0=30.0,\n",
    "                                hidden_omega_0=30.0,\n",
    "                                pos_encode_configs=pos_encode_no\n",
    "                            ).to(device)\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "    \n",
    "if args.using_cosoptim:\n",
    "    optim = torch.optim.Adam(params=model.parameters(), lr=args.lr, betas=(0.9, 0.99), eps=1e-15, weight_decay=0)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer = optim,T_max = args.T_max,eta_min=args.eta_min)\n",
    "else:\n",
    "    optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "    scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "# torch.optim.lr_scheduler.StepLR(optim, step_size  = step, gamma = 0.8)\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).reshape(H * W, 3)[None, ...].to(device)\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        # print(optim.param_groups[0]['lr'])\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].to(device)\n",
    "        b_indices = b_indices.to(device)\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            # print(b_coords.size())\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        psnr_values.append(psnr.item())\n",
    "\n",
    "    #Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        if args.inr_model == 'incode' and 30 < step:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's loss is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "        \n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | PSNR: {:.4f} | SSIM:{:.4f}\".format(step, \n",
    "                                                                    mse_array[step].item(),\n",
    "                                                                    psnr.item(),ms_ssim.item()))\n",
    "        \n",
    "        # # Plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(12, 12))\n",
    "        # axes[0].set_title('Ground Truth')\n",
    "        # axes[0].imshow(im)\n",
    "        # axes[0].axis('off')\n",
    "        # axes[1].set_title('Reconstructed')\n",
    "        # axes[1].imshow(best_img)\n",
    "        # axes[1].axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n",
    "args.inr_model='siren'\n",
    "model_psnr[args.inr_model]=psnr_values\n",
    "total_time[args.inr_model]=np.array(cumulative_times)\n",
    "model_ssim[args.inr_model]=ssim_values\n",
    "# 将图像转换为PyTorch的Tensor格式\n",
    "\n",
    "\n",
    "# =使用LPIPS模型计算距离\n",
    "vgg_distance = lpips_vgg_model(original_img, reconstruct_img)\n",
    "alex_distance = lpips_alex_model(original_img, reconstruct_img)\n",
    "print(\"VGG: LPIPS distance:\", vgg_distance.item())\n",
    "print(\"ALEX: LPIPS distance:\", alex_distance.item())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result//'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result//im.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=0.1)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HO+siren\n",
    "# poly_siren\n",
    "class SineLayer(nn.Module):\n",
    "    '''\n",
    "    SineLayer is a custom PyTorch module that applies the Sinusoidal activation function to the output of a linear transformation.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        out_features (int): Number of output features.\n",
    "        bias (bool, optional): If True, the linear transformation includes a bias term. Default is True.\n",
    "        is_first (bool, optional): If it is the first layer, we initialize the weights differently. Default is False.\n",
    "        omega_0 (float, optional): Frequency scaling factor for the sinusoidal activation. Default is 30.\n",
    "        scale (float, optional): Scaling factor for the output of the sine activation. Default is 10.0.\n",
    "        init_weights (bool, optional): If True, initializes the layer's weights according to the SIREN paper. Default is True.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                is_first=False, omega_0=30, scale=10.0, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # self.linear.bias.data.fill_(10)\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                            1 / self.in_features)  \n",
    "                # self.linear.bias.data.uniform_(-0.8,0.8)    \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                            np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "                # self.linear.bias.data.uniform_(-8,8)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"\n",
    "        Siren activation\n",
    "        https://arxiv.org/abs/2006.09661\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w0=1):\n",
    "        \"\"\"\n",
    "            w0 comes from the end of section 3\n",
    "            it should be 30 for the first layer\n",
    "            and 1 for the rest\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w0 = torch.tensor(w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(self.w0*(torch.abs(x)+1)*x) \n",
    "        return torch.sin(self.w0 * x) \n",
    "    def extra_repr(self):\n",
    "        return \"w0={}\".format(self.w0)\n",
    "    \n",
    "    \n",
    "\n",
    "class PolySiren(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,activate='ReLU',norm_type='None'\n",
    "        ) -> None:\n",
    "        super(PolySiren, self).__init__()\n",
    "        input_dim = 2\n",
    "\n",
    "        input_dim = 2 \n",
    "        hidden_channel=256\n",
    "        \n",
    "        \n",
    "        w1=100\n",
    "        w2=2\n",
    "        w3=1\n",
    "        w4=1\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.linear1=SineLayer(input_dim,hidden_channel,omega_0=w1,is_first=True)\n",
    "        if norm_type=='LayerNorm':\n",
    "            # self.norm1=nn.LayerNorm(hidden_channel)\n",
    "            self.norm2=nn.LayerNorm(hidden_channel)\n",
    "            self.norm3=nn.LayerNorm(hidden_channel)\n",
    "            self.norm4=nn.LayerNorm(hidden_channel)\n",
    "            # self.norm5=nn.LayerNorm(hidden_channel)\n",
    "            # self.norm6=nn.LayerNorm(hidden_channel)\n",
    "        elif norm_type=='BatchNorm1d':\n",
    "            self.norm1=nn.BatchNorm1d(65536)\n",
    "            self.norm2=nn.BatchNorm1d(65536)\n",
    "            self.norm3=nn.BatchNorm1d(65536)\n",
    "            self.norm4=nn.BatchNorm1d(65536)\n",
    "        elif norm_type=='None':\n",
    "            self.norm1=nn.Identity()\n",
    "            self.norm2=nn.Identity()\n",
    "            self.norm3=nn.Identity()\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.linear2=SineLayer(hidden_channel,hidden_channel,omega_0=w2)\n",
    "        self.linear3=SineLayer(hidden_channel,hidden_channel,omega_0=w3)\n",
    "        self.linear4=SineLayer(hidden_channel,hidden_channel,omega_0=w4)\n",
    "        if activate=='ReLU':\n",
    "            self.nolinear1=nn.ReLU()\n",
    "            self.nolinear2=nn.ReLU()\n",
    "            self.nolinear3=nn.ReLU()\n",
    "        if activate=='Siren':\n",
    "            self.nolinear1=Siren(w1)\n",
    "            self.nolinear2=Siren(w2)\n",
    "            self.nolinear3=Siren(w3)\n",
    "            self.nolinear4=Siren(w4)\n",
    "            self.nolinear5=Siren(1)\n",
    "            self.nolinear6=Siren(1)\n",
    "        layers = []\n",
    "        layers.append(SineLayer(hidden_channel, 3,is_first=True))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input\n",
    "\n",
    "        \n",
    "        x = self.nolinear1(self.linear1(x))\n",
    "        x = self.nolinear2(self.norm2(x+x*self.linear2(x)))\n",
    "        x = self.nolinear3(self.norm3(x+x*self.linear3(x)))\n",
    "        x = self.nolinear4(self.norm4(x+x*self.linear4(x)))\n",
    "        x = self.layers(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "args.inr_model ='siren'\n",
    "args.lr=6e-3\n",
    "model = PolySiren(activate='Siren',norm_type='LayerNorm').to(device)\n",
    "\n",
    "# print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n",
    "\n",
    "\n",
    "# Optimizer setup\n",
    "if args.inr_model == 'wire':\n",
    "    args.lr = args.lr * min(1, args.maxpoints / (H * W))\n",
    "    \n",
    "if args.using_cosoptim:\n",
    "    optim = torch.optim.Adam(params=model.parameters(), lr=args.lr, betas=(0.9, 0.99), eps=1e-15, weight_decay=0)\n",
    "    scheduler = lr_scheduler.CosineAnnealingLR(optimizer = optim,T_max = args.T_max,eta_min=args.eta_min)\n",
    "else:\n",
    "    optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "    scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "# torch.optim.lr_scheduler.StepLR(optim, step_size  = step, gamma = 0.8)\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "psnr_values = []\n",
    "ssim_values = []\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))\n",
    "\n",
    "# Generate coordinate grid\n",
    "coords = utils.get_coords(H, W, dim=2)[None, ...]\n",
    "\n",
    "# Convert input image to a tensor and reshape\n",
    "gt = torch.tensor(im).reshape(H * W, 3)[None, ...].to(device)\n",
    "\n",
    "# Initialize a tensor for reconstructed data\n",
    "rec = torch.zeros_like(gt)\n",
    "cumulative_times = []\n",
    "start_time = time.time()  \n",
    "for step in tqdm(range(args.niters)):\n",
    "    # Randomize the order of data points for each iteration\n",
    "    indices = torch.randperm(H*W)\n",
    "\n",
    "    # Process data points in batches\n",
    "    for b_idx in range(0, H*W, args.maxpoints):\n",
    "        # print(optim.param_groups[0]['lr'])\n",
    "        b_indices = indices[b_idx:min(H*W, b_idx+args.maxpoints)]\n",
    "        b_coords = coords[:, b_indices, ...].to(device)\n",
    "        b_indices = b_indices.to(device)\n",
    "        \n",
    "        # Calculate model output\n",
    "        if args.inr_model == 'incode':\n",
    "            model_output, coef = model(b_coords)  \n",
    "        else:\n",
    "            # print(b_coords.size())\n",
    "            model_output = model(b_coords) \n",
    "\n",
    "        # Update the reconstructed data\n",
    "        with torch.no_grad():\n",
    "            rec[:, b_indices, :] = model_output\n",
    "\n",
    "        # Calculate the output loss\n",
    "        output_loss = ((model_output - gt[:, b_indices, :])**2).mean()\n",
    "        \n",
    "        if args.inr_model == 'incode':\n",
    "            # Calculate regularization loss for 'incode' model\n",
    "            a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "            reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                    args.b_coef * torch.relu(-b_coef) + \\\n",
    "                    args.c_coef * torch.relu(-c_coef) + \\\n",
    "                    args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "            # Total loss for 'incode' model\n",
    "            loss = output_loss + reg_loss \n",
    "        else: \n",
    "            # Total loss for other models\n",
    "            loss = output_loss\n",
    "\n",
    "        # Perform backpropagation and update model parameters\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "    # Calculate PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array[step] = ((gt - rec)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        psnr_values.append(psnr.item())\n",
    "\n",
    "    #Adjust learning rate using a scheduler if applicable\n",
    "    if args.using_schedular:\n",
    "        if args.inr_model == 'incode' and 30 < step:\n",
    "            scheduler.step()\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "    # Prepare reconstructed image for visualization\n",
    "    imrec = rec[0, ...].reshape(H, W, 3).detach().cpu().numpy()\n",
    "    current_total_time = time.time() - start_time\n",
    "    # 将当前的累积时间添加到列表中\n",
    "    cumulative_times.append(current_total_time)\n",
    "    # Check if the current iteration's loss is the best so far\n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_img = imrec\n",
    "        best_img = (best_img - best_img.min()) / (best_img.max() - best_img.min())\n",
    "        \n",
    "    original_img = torch.tensor(im).permute(2, 0, 1).unsqueeze(0)\n",
    "    reconstruct_img = torch.tensor(best_img).permute(2, 0, 1).unsqueeze(0)\n",
    "    ms_ssim = ssim(original_img, reconstruct_img, data_range=1, size_average=False)\n",
    "    ssim_values.append(ms_ssim.item())\n",
    "    # Display intermediate results at specified intervals\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.5f} | PSNR: {:.4f} | SSIM:{:.4f}\".format(step, \n",
    "                                                                    mse_array[step].item(),\n",
    "                                                                    psnr.item(),ms_ssim.item()))\n",
    "        \n",
    "        # # Plot\n",
    "        # fig, axes = plt.subplots(1, 2, figsize=(12, 12))\n",
    "        # axes[0].set_title('Ground Truth')\n",
    "        # axes[0].imshow(im)\n",
    "        # axes[0].axis('off')\n",
    "        # axes[1].set_title('Reconstructed')\n",
    "        # axes[1].imshow(best_img)\n",
    "        # axes[1].axis('off')\n",
    "        # plt.show()\n",
    "\n",
    "# Print maximum PSNR achieved during training\n",
    "args.inr_model='HO_siren'\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('Max SSIM:', max(ssim_values))\n",
    "print('--------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_img_save_name='/root/autodl-tmp/INCODE-main/result//'+args.inr_model+'_best_img.png'\n",
    "cv2.imwrite('/root/autodl-tmp/INCODE-main/result/im.png',im[:,:, ::-1]*255)\n",
    "cv2.imwrite(best_img_save_name,best_img[:,:, ::-1]*255)\n",
    "\n",
    "\n",
    "image1 = cv2.imread('/root/autodl-tmp/INCODE-main/result//im.png')\n",
    "image2 = cv2.imread(best_img_save_name)\n",
    "\n",
    "# 确保图像为同一尺寸\n",
    "image1 = cv2.resize(image1, (image2.shape[1], image2.shape[0]))\n",
    "\n",
    "# 计算差异\n",
    "difference = cv2.absdiff(image1, image2)\n",
    "\n",
    "# 将差异转换为灰度图，以便更清晰地看到差异\n",
    "gray_difference = cv2.cvtColor(difference, cv2.COLOR_BGR2GRAY)/255\n",
    "\n",
    "# 显示差异\n",
    "plt.figure(figsize=(12, 12))\n",
    "plt.subplot(1, 3, 1), plt.imshow(cv2.cvtColor(image1, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 1'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 2), plt.imshow(cv2.cvtColor(image2, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Image 2'), plt.xticks([]), plt.yticks([])\n",
    "\n",
    "plt.subplot(1, 3, 3), plt.imshow(gray_difference, cmap='jet',vmin=0,vmax=0.1)\n",
    "plt.title('Difference'), plt.xticks([]), plt.yticks([])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
