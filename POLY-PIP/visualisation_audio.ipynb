{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9452a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import argparse\n",
    "import cv2\n",
    "from scipy import io\n",
    "from tqdm.notebook import tqdm\n",
    "import io\n",
    "from IPython.display import Audio\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchaudio\n",
    "import torchaudio.transforms as transforms\n",
    "\n",
    "from modules import utils\n",
    "from modules.models import INR\n",
    "from torchsummary import summary\n",
    "from modules.encoding import Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7de91a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='INCODE')\n",
    "\n",
    "# Shared Parameters\n",
    "parser.add_argument('--input',type=str, default='/root/autodl-tmp/INCODE-main/poly_data/incode_data/Audio/gt_bach.wav', help='Input image path')\n",
    "parser.add_argument('--inr_model',type=str, default='incode', help='[gauss, mfn, relu, siren, wire, wire2d, ffn, incode]')\n",
    "parser.add_argument('--lr',type=float, default=9e-5, help='Learning rate')\n",
    "parser.add_argument('--using_schedular', type=bool, default=True, help='Whether to use schedular')\n",
    "parser.add_argument('--scheduler_b', type=float, default=0.1, help='Learning rate scheduler')\n",
    "parser.add_argument('--maxpoints', type=int, default=256*256, help='Batch size')\n",
    "parser.add_argument('--niters', type=int, default=501, help='Number if iterations')\n",
    "parser.add_argument('--steps_til_summary', type=int, default=100, help='Number of steps till summary visualization')\n",
    "\n",
    "# INCODE Parameters\n",
    "parser.add_argument('--a_coef',type=float, default=0.1993, help='a coeficient')\n",
    "parser.add_argument('--b_coef',type=float, default=0.0196, help='b coeficient')\n",
    "parser.add_argument('--c_coef',type=float, default=0.0588, help='c coeficient')\n",
    "parser.add_argument('--d_coef',type=float, default=0.0269, help='d coeficient')\n",
    "\n",
    "\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c268067e",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d16c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = utils.AudioFile(args.input)\n",
    "dataloader = DataLoader(audio, shuffle=True, batch_size=1, pin_memory=True, num_workers=0)\n",
    "rate, coords, ground_truth = next(iter(dataloader))\n",
    "\n",
    "coords = coords.to(device)\n",
    "gt = ground_truth.to(device)\n",
    "rate = rate[0].item()\n",
    "\n",
    "Audio(ground_truth.squeeze().numpy(), rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab2563",
   "metadata": {},
   "source": [
    "## Defining Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c717b7",
   "metadata": {},
   "source": [
    "### Defining desired Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cdf32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Frequency Encoding\n",
    "pos_encode_freq = {'type':'frequency', 'use_nyquist': True, 'mapping_input': len(audio.data)}\n",
    "\n",
    "# Gaussian Encoding\n",
    "pos_encode_gaus = {'type':'gaussian', 'scale_B': 10, 'mapping_input': 256}\n",
    "\n",
    "# No Encoding\n",
    "pos_encode_no = {'type': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c1145d",
   "metadata": {},
   "source": [
    "### Model Configureations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f3ca41",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef27973",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3cfffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt.squeeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d602b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Harmonizer Configurations\n",
    "# MLP_configs={'task': 'audio',\n",
    "#              'in_channels': 50,             \n",
    "#              'hidden_channels': [50, 32, 4],\n",
    "#              'mlp_bias':0.3120,\n",
    "#              'activation_layer': nn.SiLU,\n",
    "#              'sample_rate': rate,\n",
    "#              'GT': gt.squeeze(-1)\n",
    "#             }\n",
    "\n",
    "# ### Model Configurations\n",
    "# model = INR(args.inr_model).run(in_features=1,\n",
    "#                                 out_features=1, \n",
    "#                                 hidden_features=256,\n",
    "#                                 hidden_layers=3,\n",
    "#                                 first_omega_0=3000.0,\n",
    "#                                 hidden_omega_0=30.0,\n",
    "#                                 pos_encode_configs=pos_encode_no, \n",
    "#                                 MLP_configs = MLP_configs\n",
    "#                                ).to(device)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb63a7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poly_siren\n",
    "class SineLayer(nn.Module):\n",
    "    '''\n",
    "    SineLayer is a custom PyTorch module that applies the Sinusoidal activation function to the output of a linear transformation.\n",
    "\n",
    "    Args:\n",
    "        in_features (int): Number of input features.\n",
    "        out_features (int): Number of output features.\n",
    "        bias (bool, optional): If True, the linear transformation includes a bias term. Default is True.\n",
    "        is_first (bool, optional): If it is the first layer, we initialize the weights differently. Default is False.\n",
    "        omega_0 (float, optional): Frequency scaling factor for the sinusoidal activation. Default is 30.\n",
    "        scale (float, optional): Scaling factor for the output of the sine activation. Default is 10.0.\n",
    "        init_weights (bool, optional): If True, initializes the layer's weights according to the SIREN paper. Default is True.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, in_features, out_features, bias=True,\n",
    "                 is_first=False, omega_0=30, scale=10.0, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.omega_0 = omega_0\n",
    "        self.is_first = is_first\n",
    "        \n",
    "        self.in_features = in_features\n",
    "        self.linear = nn.Linear(in_features, out_features, bias=bias)\n",
    "        \n",
    "        if init_weights:\n",
    "            self.init_weights()\n",
    "    \n",
    "    def init_weights(self):\n",
    "        # self.linear.bias.data.fill_(10)\n",
    "        with torch.no_grad():\n",
    "            if self.is_first:\n",
    "                self.linear.weight.uniform_(-1 / self.in_features, \n",
    "                                             1 / self.in_features)      \n",
    "            else:\n",
    "                self.linear.weight.uniform_(-np.sqrt(6 / self.in_features) / self.omega_0, \n",
    "                                             np.sqrt(6 / self.in_features) / self.omega_0)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "\n",
    "class Siren(nn.Module):\n",
    "    \"\"\"\n",
    "        Siren activation\n",
    "        https://arxiv.org/abs/2006.09661\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, w0=1):\n",
    "        \"\"\"\n",
    "            w0 comes from the end of section 3\n",
    "            it should be 30 for the first layer\n",
    "            and 1 for the rest\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.w0 = torch.tensor(w0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return torch.sin(self.w0*(torch.abs(x)+1)*x) \n",
    "        return torch.sin(self.w0 * x) \n",
    "    def extra_repr(self):\n",
    "        return \"w0={}\".format(self.w0)\n",
    "    \n",
    "    \n",
    "\n",
    "class PolySiren(nn.Module):\n",
    "    \n",
    "    def __init__(\n",
    "        self,activate='ReLU',norm_type='None'\n",
    "        ) -> None:\n",
    "        super(PolySiren, self).__init__()\n",
    "        input_dim = 2\n",
    "\n",
    "        input_dim = 1\n",
    "        hidden_channel=256\n",
    "        self.linear1=SineLayer(input_dim,hidden_channel,is_first=True)\n",
    "        if norm_type=='LayerNorm':\n",
    "            self.norm1=nn.LayerNorm(hidden_channel,eps=0.0000001)\n",
    "            self.norm2=nn.LayerNorm(hidden_channel,eps=0.0000001)\n",
    "            self.norm3=nn.LayerNorm(hidden_channel,eps=0.0000001)\n",
    "            self.norm4=nn.LayerNorm(hidden_channel,eps=0.0000001)\n",
    "        elif norm_type=='BatchNorm1d':\n",
    "            self.norm1=nn.BatchNorm1d(65536)\n",
    "            self.norm2=nn.BatchNorm1d(65536)\n",
    "            self.norm3=nn.BatchNorm1d(65536)\n",
    "            self.norm4=nn.BatchNorm1d(65536)\n",
    "        elif norm_type=='None':\n",
    "            self.norm1=nn.Identity()\n",
    "            self.norm2=nn.Identity()\n",
    "            self.norm3=nn.Identity()\n",
    "            \n",
    "            \n",
    "            \n",
    "        self.linear2=SineLayer(hidden_channel,hidden_channel)\n",
    "        self.linear3=SineLayer(hidden_channel,hidden_channel)\n",
    "        self.linear4=SineLayer(hidden_channel,hidden_channel)\n",
    "        \n",
    "        if activate=='ReLU':\n",
    "            self.nolinear1=nn.ReLU()\n",
    "            self.nolinear2=nn.ReLU()\n",
    "            self.nolinear3=nn.ReLU()\n",
    "        if activate=='Siren':\n",
    "            self.nolinear1=Siren(3000)\n",
    "            self.nolinear2=Siren(8)\n",
    "            self.nolinear3=Siren(2)\n",
    "            self.nolinear4=Siren(2)\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(hidden_channel, 1))\n",
    "        # layers.append(nn.Sigmoid())\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    def forward(self, input):\n",
    "\n",
    "        x = input\n",
    "\n",
    "        \n",
    "        x = self.nolinear1(self.linear1(x))\n",
    "        x = self.nolinear2(self.norm2(x+x*self.linear2(x)))\n",
    "        x = self.nolinear3(self.norm3(x+x*self.linear3(x)))\n",
    "        x = self.nolinear4(self.norm4(x+x*self.linear4(x)))\n",
    "        # x = self.nolinear3(x)\n",
    "        x = self.layers(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "args.lr=8e-4\n",
    "args.inr_model = 'siren'\n",
    "model = PolySiren(activate='Siren',norm_type='LayerNorm').to(device)\n",
    "\n",
    "print(model)\n",
    "num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total number of parameters: {num_params/1e6}(M)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53acf0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Model Configurations\n",
    "# args.inr_model='siren'\n",
    "# args.lr= 1e-4\n",
    "# model = INR(args.inr_model).run(in_features=1,\n",
    "#                                 out_features=1, \n",
    "#                                 hidden_features=256,\n",
    "#                                 hidden_layers=3,\n",
    "#                                 first_omega_0=3000.0,\n",
    "#                                 hidden_omega_0=30.0,\n",
    "#                                 pos_encode_configs=pos_encode_no\n",
    "#                                ).to(device)\n",
    "# print(model)\n",
    "# num_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "# print(f'Total number of parameters: {num_params/1e6}(M)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db268c3d",
   "metadata": {},
   "source": [
    "## Training Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f58b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer setup\n",
    "optim = torch.optim.Adam(lr=args.lr, params=model.parameters())\n",
    "scheduler = lr_scheduler.LambdaLR(optim, lambda x: args.scheduler_b ** min(x / args.niters, 1))\n",
    "\n",
    "# Initialize lists for PSNR and MSE values\n",
    "psnr_values = []\n",
    "mse_array = torch.zeros(args.niters, device=device)\n",
    "\n",
    "# Initialize best loss value as positive infinity\n",
    "best_loss = torch.tensor(float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa59bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "for step in tqdm(range(args.niters)):\n",
    "    \n",
    "    # Calculate model output\n",
    "    if args.inr_model == 'incode':\n",
    "        model_output, coef = model(coords)  \n",
    "    else:\n",
    "        model_output = model(coords) \n",
    "    \n",
    "    # Calculate the output loss\n",
    "    output_loss = ((model_output - gt)**2).mean()\n",
    "    \n",
    "    if args.inr_model == 'incode':\n",
    "        # Calculate regularization loss for 'incode' model\n",
    "        a_coef, b_coef, c_coef, d_coef = coef[0]  \n",
    "        reg_loss = args.a_coef * torch.relu(-a_coef) + \\\n",
    "                   args.b_coef * torch.relu(-b_coef) + \\\n",
    "                   args.c_coef * torch.relu(-c_coef) + \\\n",
    "                   args.d_coef * torch.relu(-d_coef)\n",
    "\n",
    "        # Total loss for 'incode' model\n",
    "        loss = output_loss + reg_loss \n",
    "    else: \n",
    "        # Total loss for other models\n",
    "        loss = output_loss\n",
    "            \n",
    "    # Perform backpropagation and update model parameters\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "    if args.using_schedular:\n",
    "        scheduler.step()\n",
    "    \n",
    "    # Calculate PSNR\n",
    "    with torch.no_grad():\n",
    "        mse_array[step] = ((model_output - gt)**2).mean().item()\n",
    "        psnr = -10*torch.log10(mse_array[step])\n",
    "        psnr_values.append(psnr.item())\n",
    "    \n",
    "    # Display GT, Reconstructed audio, and Error\n",
    "    if step % args.steps_til_summary == 0:\n",
    "        print(\"Epoch: {} | Total Loss: {:.6f} | PSNR: {:.4f}\".format(step, loss.item(), psnr.item()))\n",
    "\n",
    "        fig, axes = plt.subplots(1, 3, figsize=(18, 3))\n",
    "        axes[0].plot(coords.squeeze().detach().cpu().numpy(), gt.squeeze().detach().cpu().numpy())\n",
    "        axes[0].set_ylim(-1, 1)\n",
    "        axes[0].set_title('Ground Truth')\n",
    "        axes[1].plot(coords.squeeze().detach().cpu().numpy(), model_output.squeeze().detach().cpu().numpy())\n",
    "        axes[1].set_ylim(-1, 1)\n",
    "        axes[1].set_title('Reconstructed')\n",
    "        axes[2].plot(coords.squeeze().detach().cpu().numpy(), (model_output - gt).squeeze().detach().cpu().numpy())\n",
    "        axes[2].set_ylim(-0.6, 0.6)\n",
    "        axes[2].set_title('Error')\n",
    "        plt.show()\n",
    "\n",
    "    # Check if the current iteration's loss is the best so far        \n",
    "    if (mse_array[step] < best_loss) or (step == 0):\n",
    "        best_loss = mse_array[step]\n",
    "        best_audio = model_output.squeeze().detach().cpu().numpy()\n",
    "\n",
    "\n",
    "    \n",
    "# Print maximum PSNR achieved during training\n",
    "print('--------------------')\n",
    "print('Max PSNR:', max(psnr_values))\n",
    "print('--------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3117fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(best_audio, rate=rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86e4b9e",
   "metadata": {},
   "source": [
    "# Convergance Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dc2a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'font': 'Times New Roman', 'size': 12}\n",
    "\n",
    "plt.figure()\n",
    "axfont = {'family' : 'Times New Roman', 'weight' : 'regular', 'size'   : 10}\n",
    "plt.rc('font', **axfont)\n",
    "\n",
    "plt.plot(np.arange(len(psnr_values[:-1])), psnr_values[:-1], label = f\"{(args.inr_model).upper()}\")\n",
    "plt.xlabel('# Epochs', fontdict=font)\n",
    "plt.ylabel('PSNR (dB)', fontdict=font)\n",
    "plt.title('Audio Representation', fontdict={'family': 'Times New Roman', 'size': 12, 'weight': 'bold'})\n",
    "plt.legend()\n",
    "plt.grid(True, color='lightgray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
